{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë² ì´ì¦ˆ ì •ë¦¬\n",
    "* ë² ì´ì¦ˆ ì •ë¦¬ë€, í™•ë¥  ë³€ìˆ˜ì˜ ì¡°ê±´ë¶€ í™•ë¥  ë¶„í¬ì™€ ì£¼ë³€ë¶€ í™•ë¥  ë¶„í¬ë¥¼ ì—°ê´€ ì§“ëŠ” í™•ë¥  ì´ë¡ ìœ¼ë¡œ ë‘ í™•ë¥  ì‚¬ì´ì˜ ì¡´ì¬í•˜ëŠ” ê´€ê³„ë¥¼ ì„¤ëª…í•˜ëŠ” ê²ƒìœ¼ë¡œ ì¡°ê±´ë¶€ í™•ë¥ ì´ë¼ê³ ë„ í•¨\n",
    "* ì´ëŠ” P(A|B)= P(Aâˆ©B) / P(B) = P(A) * P(B|A) / P(B) ì˜ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŒ\n",
    "* P(A|B) ë€, ì‚¬ê±´ Bê°€ ë°œìƒí•  ë•Œ Aì˜ ì¡°ê±´ë¶€ í™•ë¥ ë¡œì¨ ì‚¬í›„ í™•ë¥ ì´ë¼ í•˜ëŠ”ë° ì´ëŠ” P(A|B)ê°€ ì‚¬ê±´ Bì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ì— ì˜ì¡´í•˜ê¸° ë•Œë¬¸\n",
    "\n",
    "           \n",
    "\n",
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ë¶„ë¥˜\n",
    "* ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ(ë˜ëŠ” ë² ì´ì§€ì•ˆ) ë¶„ë¥˜ëŠ” ì§€ë„ í•™ìŠµì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ë¶„ë¥˜ ì¤‘ í•˜ë‚˜\n",
    "* ì´ ë¶„ë¥˜ëŠ” ë¶„ë¥˜ë¥¼ ìœ„í•´ì„œ ë² ì´ì¦ˆ ë£°ì„ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ìˆìŒ\n",
    "* P(A|B) ì—ì„œ A ì‚¬ê±´ì´ ì¼ì–´ë‚˜ê²Œ í•˜ëŠ” B ì‚¬\n",
    "íŠ¹ì§•(feature)ê°€ ë…ë¦½ì •ì´ë¼ê³  ê°€ì •í•˜ë©´ 1ê°œ ì´ìƒ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### X ì¡°ê±´ì¼ë•Œ P ì¼ í™•ë¥ ?\n",
    "\n",
    "- P(Y|X)  =   P(Yâˆ©X) / P(X)   =   P(X|Y) * P(Y) / P(X)\n",
    " \n",
    " \n",
    "### ë¶„ë¥˜ ë¬¸ì œ : X1, X2,... Xn ì¼ë•Œ â–¶     C1 ?  C2 ? ...\n",
    "\n",
    "  - P(C1|X1, X2, ....Xn) = P(X1,X2,....Xn | C1) * P(C1) / P(X1, X2, ...Xn)\n",
    "  \n",
    "  Vs\n",
    "  \n",
    "  - P(C2|X1, X2, ....Xn) = P(X1,X2,....Xn | C2) * P(C2) / P(X1, X2, ...Xn)\n",
    "  \n",
    "  \n",
    "  ==> \n",
    "  \n",
    "  - P(X1,X2,....Xn | C1) * P(C1) Vs P(X1,X2,....Xn | C2) * P(C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P(X1,X2,....Xn | C1) ê³„ì‚° How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğ‘ƒ(ğ‘‹1,ğ‘‹2,â€¦, ,â€¦, ğ‘‹n|ğ¶ğ‘–) = ğ‘ƒ(ğ‘‹1ğ¶ğ‘–)Ã—ğ‘ƒ(ğ‘‹2ğ¶ğ‘–)Ã—â‹¯Ã—ğ‘ƒ(ğ‘‹ğ‘ğ¶ğ‘–)\n",
    "\n",
    "â€» X1, X2, ...  Xn ê°ê°ì˜ ì¡°ê±´ë“¤ì´ ì„œë¡œ ë…ë¦½ì´ë¼ëŠ” ê°€ì • í•„ìˆ˜!!!!!\n",
    "\n",
    "==> Naive Bayes Classfier:  Naice \"ìˆœì§„í•œ, ì²œì§„í•œ,  ì•ˆì¼í•œ?   ëŒ€ì¶©ëŒ€ì¶©????\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 3,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 18,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFilter:\n",
    "    \"\"\"ë² ì´ì§€ì•ˆ í•„í„°\"\"\"\n",
    "    def __init__(self):\n",
    "        self.words = set() # ì¶œí˜„í•œ ë‹¨ì–´ ê¸°ë¡\n",
    "        self.word_dict = {} # ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ì–´ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡\n",
    "        self.category_dict = {} # ì¹´í…Œê³ ë¦¬ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡\n",
    "        \n",
    "    #í˜•íƒœì†Œ ë¶„ì„í•˜ê¸° \n",
    "    def split(self, text):\n",
    "        results = []\n",
    "        twitter = Twitter()\n",
    "        \n",
    "        #ë‹¨ì–´ì˜ ê¸°ë³¸í˜• ì‚¬ìš©\n",
    "        malist = twitter.pos(text, norm = True, stem = True)\n",
    "        for word in malist :\n",
    "            # ì–´ë¯¸/ì¡°ì‚¬/êµ¬ë‘ì  ë“±ì€ ëŒ€ìƒì—ì„œ ì œì™¸\n",
    "            if not word[1] in [\"Josa\",\"Eomi\", \"Punctuation\"] :\n",
    "                results.append(word[0])\n",
    "        return results\n",
    "    \n",
    "    # ë‹¨ì–´ì™€ ì¹´í…Œê³ ë¦¬ì˜ ì¶œí˜„ íšŸìˆ˜ ì„¸ê¸° \n",
    "    def inc_word(self, word, category):\n",
    "        #ë‹¨ì–´ë¥¼ ì¹´í…Œê³ ë¦¬ì— ì¶”ê°€\n",
    "        if not category in self.word_dict:\n",
    "            self.word_dict[category] = {}\n",
    "        if not word in self.word_dict[category]:\n",
    "            self.word_dict[category][word] = 0\n",
    "        self.word_dict[category][word] += 1\n",
    "        self.words.add(word)\n",
    "        \n",
    "    def inc_category(self, category):\n",
    "        # ì¹´í…Œê³ ë¦¬ ê³„ì‚°í•˜ê¸°\n",
    "        if not category in self.category_dict:\n",
    "            self.category_dict[category] = 0\n",
    "        self.category_dict[category] += 1\n",
    "        \n",
    "    # í…ìŠ¤íŠ¸ í•™ìŠµí•˜ê¸° \n",
    "    def fit(self, text, category):\n",
    "        \"\"\"í…ìŠ¤íŠ¸ í•™ìŠµ\"\"\"\n",
    "        word_list = self.split(text)\n",
    "        for word in word_list:\n",
    "            self.inc_word(word, category)\n",
    "        self.inc_category(category)\n",
    "        \n",
    "        \n",
    "    # ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ì— ì ìˆ˜ ë§¤ê¸°ê¸° \n",
    "    def score(self, words, category):\n",
<<<<<<< HEAD
    "        # P(Ci)  #ê´‘ê³    # ì¤‘ìš”\n",
=======
    "        # P(Ci)\n",
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
    "        score = math.log(self.category_prob(category))  # ê°’ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ë‹¤ìš´ í”Œë¡œê°€ ë°œìƒí•  ìˆ˜ ìˆì–´ì„œ log ì‚¬ìš©\n",
    "        \n",
    "        # P(X1,X2,..Xn  âˆ© Ci)\n",
    "        for word in words:\n",
    "            score += math.log(self.word_prob(word, category))     #P(Xk âˆ© Ci)\n",
    "            # P(Ci)* P(X1 âˆ© Ci) * P(X2 âˆ© Ci) * ........\n",
    "            # log A  + log B + logC= log ABC\n",
    "            \n",
    "        return score\n",
    "    \n",
    "    # ì˜ˆì¸¡í•˜ê¸° --- (â€»5)\n",
    "    def predict(self, text):\n",
    "        best_category = None\n",
    "        max_score = -sys.maxsize   # ì‹œìŠ¤í…œ(64bit or 32bit) ìƒ ê°€ì¥ í° ìˆ«ì ==> ìµœì†Œê°’ ì§€ì •.  - ê°’ì´ê¸°ì— 0ì„ ìµœì†Œë¡œ ë†“ì„ ìˆ˜ ì—†ìŒ\n",
    "        print(max_score)\n",
    "        words = self.split(text)\n",
<<<<<<< HEAD
    "        print(words)\n",
    "        score_list = []\n",
    "        for category in self.category_dict.keys():\n",
    "            print(category)\n",
    "            score = self.score(words, category)\n",
    "            print(score)\n",
=======
    "        score_list = []\n",
    "        for category in self.category_dict.keys():\n",
    "            score = self.score(words, category)\n",
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
    "            score_list.append((category, score))\n",
    "            print(category, score) \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_category = category\n",
    "        return best_category, score_list\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ ë‚´ë¶€ì˜ ë‹¨ì–´ ì¶œí˜„ íšŸìˆ˜ êµ¬í•˜ê¸°\n",
    "    def get_word_count(self, word, category):\n",
    "        if word in self.word_dict[category]:\n",
    "            return self.word_dict[category][word]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ ê³„ì‚°:   n(Ci) / sum(Cn)\n",
    "    def category_prob(self, category):\n",
    "        sum_categories = sum(self.category_dict.values())\n",
    "        category_v = self.category_dict[category]\n",
    "        return category_v / sum_categories\n",
    "    \n",
    "    # ì¹´í…Œê³ ë¦¬ ë‚´ë¶€ì˜ ë‹¨ì–´ ì¶œí˜„ ë¹„ìœ¨ ê³„ì‚° :  P(Aâˆ©B)\n",
    "    def word_prob(self, word, category):\n",
    "        n = self.get_word_count(word, category) + 1   # í•™ìŠµ ì‚¬ì „ì— ì—†ëŠ” ë‹¨ì–´ê°€ ë‚˜ì˜¤ë©´ ì¹´í…Œê³ ë¦¬ì˜ í™•ë¥ ì´ 0ì´ ë˜ì–´ë²„ë ¤ì„œ 1ì„ ë”í•´ì¤Œ\n",
    "        d = sum(self.word_dict[category].values()) + len(self.words)\n",
    "        return n/d"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 8,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "bf = BayesianFilter()\n",
    "print(bf.words)  # ì¶œí˜„í•œ ë‹¨ì–´ ê¸°ë¡\n",
    "print(bf.word_dict)  # ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ì˜ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡\n",
    "print(bf.category_dict)  # ì¹´í…Œê³ ë¦¬ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 12,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜•íƒœì†Œ ë¶„ì„ ì¤‘ê°„ê³¼ì •\n",
    "\n",
    "#í˜•íƒœì†Œ ë¶„ì„í•˜ê¸° --- (â€»1)\n",
    "def split_test(text):\n",
    "    results = []\n",
    "    twitter = Twitter()\n",
    "\n",
    "    #ë‹¨ì–´ì˜ ê¸°ë³¸í˜• ì‚¬ìš©\n",
    "    malist = twitter.pos(text, norm = True, stem = True)\n",
    "    print(\"total : \", malist)\n",
    "    \n",
    "    for word in malist :\n",
    "        # ì–´ë¯¸/ì¡°ì‚¬/êµ¬ë‘ì  ë“±ì€ ëŒ€ìƒì—ì„œ ì œì™¸\n",
    "        if not word[1] in [\"Josa\",\"Eomi\", \"Punctuation\"] :\n",
    "            results.append(word[0])\n",
    "    \n",
    "    print(\"ë¶„ì„ëŒ€ìƒ\", results)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 15,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "total :  [('ì•„ë²„ì§€', 'Noun'), ('ê°€ë°©', 'Noun'), ('ì—', 'Josa'), ('ë“¤ì–´ê°€ë‹¤', 'Verb')]\n",
      "ë¶„ì„ëŒ€ìƒ ['ì•„ë²„ì§€', 'ê°€ë°©', 'ë“¤ì–´ê°€ë‹¤']\n"
=======
      "total :  [('íŒŒê²©', 'Noun'), ('ì„¸ì¼', 'Noun'), ('-', 'Punctuation'), ('ì˜¤ëŠ˜', 'Noun'), ('ê¹Œì§€ë§Œ', 'Josa'), ('30', 'Number'), ('%', 'Punctuation'), ('í• ì¸', 'Noun')]\n",
      "ë¶„ì„ëŒ€ìƒ ['íŒŒê²©', 'ì„¸ì¼', 'ì˜¤ëŠ˜', '30', 'í• ì¸']\n",
      "\n",
      "\n",
      "total :  [('ë´„', 'Noun'), ('ê³¼', 'Josa'), ('í•¨ê»˜', 'Adverb'), ('ì°¾ì•„ì˜¤ë‹¤', 'Verb'), ('ë”°ëœ»í•˜ë‹¤', 'Adjective'), ('ì‹ ì œí’ˆ', 'Noun'), ('ì†Œì‹', 'Noun')]\n",
      "ë¶„ì„ëŒ€ìƒ ['ë´„', 'í•¨ê»˜', 'ì°¾ì•„ì˜¤ë‹¤', 'ë”°ëœ»í•˜ë‹¤', 'ì‹ ì œí’ˆ', 'ì†Œì‹']\n"
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['ì•„ë²„ì§€', 'ê°€ë°©', 'ë“¤ì–´ê°€ë‹¤']"
      ]
     },
     "execution_count": 8,
=======
       "['ë´„', 'í•¨ê»˜', 'ì°¾ì•„ì˜¤ë‹¤', 'ë”°ëœ»í•˜ë‹¤', 'ì‹ ì œí’ˆ', 'ì†Œì‹']"
      ]
     },
     "execution_count": 15,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "# split_test('ë´„ê³¼í•¨ê»˜ì°¾ì•„ì˜¨ë”°ëœ»í•œ ì‹ ì œí’ˆ ì†Œì‹')   # 'ì°¾ì•„ì˜¨' --> 'ì°¾ì•„ì˜¤ë‹¤',  'ë”°ëœ»í•œ' --> 'ë”°ëœ»í•˜ë‹¤'\n",
    "split_test('ì•„ë²„ì§€ê°€ë°©ì— ë“¤ì–´ê°€ì‹ ë‹¤')"
=======
    "split_test('ë´„ê³¼ í•¨ê»˜ ì°¾ì•„ì˜¨ ë”°ëœ»í•œ ì‹ ì œí’ˆ ì†Œì‹')   # 'ì°¾ì•„ì˜¨' --> 'ì°¾ì•„ì˜¤ë‹¤',  'ë”°ëœ»í•œ' --> 'ë”°ëœ»í•˜ë‹¤'"
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 9,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'ì˜¤ëŠ˜', 'í• ì¸', 'íŒŒê²©', '30', 'ì„¸ì¼', 'ëŒ€ë°•'}\n",
      "{'ê´‘ê³ ': {'íŒŒê²©': 2, 'ì„¸ì¼': 2, 'ì˜¤ëŠ˜': 2, '30': 2, 'í• ì¸': 5, 'ëŒ€ë°•': 1}}\n",
      "{'ê´‘ê³ ': 2}\n"
=======
      "{'30', 'í• ì¸', 'íŒŒê²©', 'ì„¸ì¼', 'ì˜¤ëŠ˜'}\n",
      "{'ê´‘ê³ ': {'íŒŒê²©': 1, 'ì„¸ì¼': 1, 'ì˜¤ëŠ˜': 1, '30': 1, 'í• ì¸': 1}}\n",
      "{'ê´‘ê³ ': 1}\n"
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ í•™ìŠµ\n",
<<<<<<< HEAD
    "bf.fit(\"íŒŒê²© ì„¸ì¼ - ì˜¤ëŠ˜ê¹Œì§€ë§Œ 30% í• ì¸ í• ì¸ í• ì¸ ëŒ€ë°• í• ì¸\", \"ê´‘ê³ \")\n",
=======
    "bf.fit(\"íŒŒê²© ì„¸ì¼ - ì˜¤ëŠ˜ê¹Œì§€ë§Œ 30% í• ì¸\", \"ê´‘ê³ \")\n",
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
    "print(bf.words)  # ì¶œí˜„í•œ ë‹¨ì–´ ê¸°ë¡\n",
    "print(bf.word_dict)  # ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ì–´ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡\n",
    "print(bf.category_dict)  # ì¹´í…Œê³ ë¦¬ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 10,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'ì˜¤ëŠ˜', 'ë¬´ë£Œ', 'ì¿ í°', 'ì„ ë¬¼', 'í• ì¸', 'ë°°ì†¡', 'íŒŒê²©', '30', 'ì„¸ì¼', 'ëŒ€ë°•'}\n",
      "{'ê´‘ê³ ': {'íŒŒê²©': 2, 'ì„¸ì¼': 2, 'ì˜¤ëŠ˜': 2, '30': 2, 'í• ì¸': 5, 'ëŒ€ë°•': 1, 'ì¿ í°': 1, 'ì„ ë¬¼': 1, 'ë¬´ë£Œ': 1, 'ë°°ì†¡': 1}}\n",
      "{'ê´‘ê³ ': 3}\n"
=======
      "{'ì¿ í°', '30', 'í• ì¸', 'ë°°ì†¡', 'íŒŒê²©', 'ì„¸ì¼', 'ë¬´ë£Œ', 'ì„ ë¬¼', 'ì˜¤ëŠ˜'}\n",
      "{'ê´‘ê³ ': {'íŒŒê²©': 1, 'ì„¸ì¼': 1, 'ì˜¤ëŠ˜': 1, '30': 1, 'í• ì¸': 1, 'ì¿ í°': 1, 'ì„ ë¬¼': 1, 'ë¬´ë£Œ': 1, 'ë°°ì†¡': 1}}\n",
      "{'ê´‘ê³ ': 2}\n"
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
     ]
    }
   ],
   "source": [
    "bf.fit(\"ì¿ í° ì„ ë¬¼ & ë¬´ë£Œ ë°°ì†¡\", \"ê´‘ê³ \")\n",
    "print(bf.words)  # ì¶œí˜„í•œ ë‹¨ì–´ ê¸°ë¡\n",
    "print(bf.word_dict)  # ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ì–´ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡\n",
    "print(bf.category_dict)  # ì¹´í…Œê³ ë¦¬ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 11,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'ìƒí™©', 'í•œì •', 'ì°¾ì•„ì˜¤ë‹¤', 'ì„ ë¬¼', 'ê¸°ê°„', 'ë˜ì–´ë‹¤', 'í• ì¸', 'ê³„ì•½', 'í”„ë¡œì íŠ¸', 'ìë‹¤', 'í˜„ëŒ€', 'ì œí’ˆ', 'ì„¸ì¼', 'í•¨ê»˜', 'ì—†ë‹¤', 'ì‹ ì œí’ˆ', 'ì§„í–‰', 'ë°±í™”ì ', '30', 'ë”°ëœ»í•˜ë‹¤', 'ì¸ê¸°', 'ì†Œì‹', 'ì˜¤ëŠ˜', 'ë¬´ë£Œ', 'ì¿ í°', 'ì¼ì •', 'í™•ì¸', 'ë³´ê³ ', 'ë°°ì†¡', 'ëŒ€ë°•', 'íšŒì˜', 'ë“±ë¡', 'ë¶€íƒë“œë¦¬ë‹¤', 'íŒŒê²©', 'ë´„'}\n",
      "{'ê´‘ê³ ': {'íŒŒê²©': 2, 'ì„¸ì¼': 4, 'ì˜¤ëŠ˜': 2, '30': 2, 'í• ì¸': 5, 'ëŒ€ë°•': 1, 'ì¿ í°': 1, 'ì„ ë¬¼': 1, 'ë¬´ë£Œ': 1, 'ë°°ì†¡': 1, 'í˜„ëŒ€': 1, 'ë°±í™”ì ': 1, 'ë´„': 1, 'í•¨ê»˜': 1, 'ì°¾ì•„ì˜¤ë‹¤': 1, 'ë”°ëœ»í•˜ë‹¤': 1, 'ì‹ ì œí’ˆ': 1, 'ì†Œì‹': 1, 'ì¸ê¸°': 1, 'ì œí’ˆ': 1, 'ê¸°ê°„': 1, 'í•œì •': 1}, 'ì¤‘ìš”': {'ì˜¤ëŠ˜': 2, 'ì¼ì •': 3, 'í™•ì¸': 1, 'í”„ë¡œì íŠ¸': 1, 'ì§„í–‰': 1, 'ìƒí™©': 1, 'ë³´ê³ ': 1, 'ê³„ì•½': 1, 'ìë‹¤': 1, 'ë¶€íƒë“œë¦¬ë‹¤': 1, 'íšŒì˜': 1, 'ë“±ë¡': 1, 'ë˜ì–´ë‹¤': 1, 'ì—†ë‹¤': 1}}\n",
      "{'ê´‘ê³ ': 6, 'ì¤‘ìš”': 5}\n"
=======
      "{'ì¿ í°', 'ë“±ë¡', 'íšŒì˜', 'í•œì •', 'ì§„í–‰', 'ë´„', 'ì°¾ì•„ì˜¤ë‹¤', 'ìƒí™©', 'ì†Œì‹', 'ë¶€íƒë“œë¦¬ë‹¤', 'ìë‹¤', 'ì¸ê¸°', 'í• ì¸', 'ì‹ ì œí’ˆ', 'í˜„ëŒ€', 'ê³„ì•½', 'ë¬´ë£Œ', 'ë˜ì–´ë‹¤', 'ê¸°ê°„', 'í”„ë¡œì íŠ¸', 'ì„ ë¬¼', 'ë°°ì†¡', 'ë°±í™”ì ', 'í•¨ê»˜', 'ë³´ê³ ', 'ì—†ë‹¤', 'ë”°ëœ»í•˜ë‹¤', '30', 'ì¼ì •', 'ì œí’ˆ', 'íŒŒê²©', 'ì„¸ì¼', 'í™•ì¸', 'ì˜¤ëŠ˜'}\n",
      "{'ê´‘ê³ ': {'íŒŒê²©': 1, 'ì„¸ì¼': 3, 'ì˜¤ëŠ˜': 1, '30': 1, 'í• ì¸': 1, 'ì¿ í°': 1, 'ì„ ë¬¼': 1, 'ë¬´ë£Œ': 1, 'ë°°ì†¡': 1, 'í˜„ëŒ€': 1, 'ë°±í™”ì ': 1, 'ë´„': 1, 'í•¨ê»˜': 1, 'ì°¾ì•„ì˜¤ë‹¤': 1, 'ë”°ëœ»í•˜ë‹¤': 1, 'ì‹ ì œí’ˆ': 1, 'ì†Œì‹': 1, 'ì¸ê¸°': 1, 'ì œí’ˆ': 1, 'ê¸°ê°„': 1, 'í•œì •': 1}, 'ì¤‘ìš”': {'ì˜¤ëŠ˜': 2, 'ì¼ì •': 3, 'í™•ì¸': 1, 'í”„ë¡œì íŠ¸': 1, 'ì§„í–‰': 1, 'ìƒí™©': 1, 'ë³´ê³ ': 1, 'ê³„ì•½': 1, 'ìë‹¤': 1, 'ë¶€íƒë“œë¦¬ë‹¤': 1, 'íšŒì˜': 1, 'ë“±ë¡': 1, 'ë˜ì–´ë‹¤': 1, 'ì—†ë‹¤': 1}}\n",
      "{'ê´‘ê³ ': 5, 'ì¤‘ìš”': 5}\n"
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
     ]
    }
   ],
   "source": [
    "bf.fit(\"í˜„ëŒ€ ë°±í™”ì  ì„¸ì¼\", \"ê´‘ê³ \")\n",
    "bf.fit(\"ë´„ê³¼ í•¨ê»˜ ì°¾ì•„ì˜¨ ë”°ëœ»í•œ ì‹ ì œí’ˆ ì†Œì‹\",\"ê´‘ê³ \")\n",
    "bf.fit(\"ì¸ê¸° ì œí’ˆ ê¸°ê°„ í•œì • ì„¸ì¼\",\"ê´‘ê³ \")\n",
    "bf.fit(\"ì˜¤ëŠ˜ ì¼ì • í™•ì¸\",\"ì¤‘ìš”\")\n",
    "bf.fit(\"í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™© ë³´ê³ \",\"ì¤‘ìš”\")\n",
    "bf.fit(\"ê³„ì•½ ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤\",\"ì¤‘ìš”\")\n",
    "bf.fit(\"íšŒì˜ ì¼ì •ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤\",\"ì¤‘ìš”\")\n",
    "bf.fit(\"ì˜¤ëŠ˜ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤\",\"ì¤‘ìš”\")\n",
    "print(bf.words)  # ì¶œí˜„í•œ ë‹¨ì–´ ê¸°ë¡\n",
    "print(bf.word_dict)  # ì¹´í…Œê³ ë¦¬ë³„ ë‹¨ì–´ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡\n",
    "print(bf.category_dict)  # ì¹´í…Œê³ ë¦¬ ì¶œí˜„ íšŸìˆ˜ ê¸°ë¡"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 19,
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "-9223372036854775807\n",
      "ê´‘ê³  -18.4515450701772\n",
      "ì¤‘ìš” -20.544675953271405\n",
      "-9223372036854775807\n",
      "ê´‘ê³  -18.4515450701772\n",
      "ì¤‘ìš” -20.544675953271405\n",
      "ê²°ê³¼ =  ê´‘ê³ \n",
      "[('ê´‘ê³ ', -18.4515450701772), ('ì¤‘ìš”', -20.544675953271405)]\n"
=======
      "ê²°ê³¼ =  ê´‘ê³ \n",
      "[('ê´‘ê³ ', -18.828961978052863), ('ì¤‘ìš”', -20.352275344181574)]\n"
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
     ]
    }
   ],
   "source": [
    "# bf = BayesianFilter()\n",
    "# # í…ìŠ¤íŠ¸ í•™ìŠµ\n",
    "# bf.fit(\"íŒŒê²© ì„¸ì¼ - ì˜¤ëŠ˜ê¹Œì§€ë§Œ 30% í• ì¸\", \"ê´‘ê³ \")\n",
    "# bf.fit(\"ì¿ í° ì„ ë¬¼ & ë¬´ë£Œ ë°°ì†¡\", \"ê´‘ê³ \")\n",
    "# bf.fit(\"í˜„ëŒ€ ë°±í™”ì  ì„¸ì¼\", \"ê´‘ê³ \")\n",
    "# bf.fit(\"ë´„ê³¼ í•¨ê»˜ ì°¾ì•„ì˜¨ ë”°ëœ»í•œ ì‹ ì œí’ˆ ì†Œì‹\",\"ê´‘ê³ \")\n",
    "# bf.fit(\"ì¸ê¸° ì œí’ˆ ê¸°ê°„ í•œì • ì„¸ì¼\",\"ê´‘ê³ \")\n",
    "# bf.fit(\"ì˜¤ëŠ˜ ì¼ì • í™•ì¸\",\"ì¤‘ìš”\")\n",
    "# bf.fit(\"í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™© ë³´ê³ \",\"ì¤‘ìš”\")\n",
    "# bf.fit(\"ê³„ì•½ ì˜ ë¶€íƒë“œë¦½ë‹ˆë‹¤\",\"ì¤‘ìš”\")\n",
    "# bf.fit(\"íšŒì˜ ì¼ì •ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤\",\"ì¤‘ìš”\")\n",
    "# bf.fit(\"ì˜¤ëŠ˜ ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤\",\"ì¤‘ìš”\")\n",
    "\n",
    "#ì˜ˆì¸¡\n",
<<<<<<< HEAD
    "bf.predict(\"ì¬ê³  ì •ë¦¬ í• ì¸, ë¬´ë£Œ ë°°ì†¡\")\n",
=======
>>>>>>> 5bed2209d8c279ffff50f44962a479717e79450d
    "pre, scorelist = bf.predict(\"ì¬ê³  ì •ë¦¬ í• ì¸, ë¬´ë£Œ ë°°ì†¡\")\n",
    "print(\"ê²°ê³¼ = \",pre)\n",
    "print(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9223372036854775807"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-sys.maxsize\n",
    "\n",
    "# sys.maxsize\n",
    "# An integer giving the maximum value a variable of type Py_ssize_t can take. Itâ€™s usually 2**31 - 1 on a 32-bit platform and 2**63 - 1 on a 64-bit platform.\n",
    "\n",
    "# https://docs.python.org/3/library/sys.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
